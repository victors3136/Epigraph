{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfl7HenI_MIg"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets \\\n",
        "                huggingface \\\n",
        "                jiwer \\\n",
        "                transformers \\\n",
        "                torchaudio \\\n",
        "                torch \\\n",
        "                tqdm\n",
        "!pip install -U -q datasets\n",
        "\n",
        "from datasets import Audio, load_dataset\n",
        "from jiwer import cer, wer\n",
        "from transformers import AutoModelForSpeechSeq2Seq, \\\n",
        "                         WhisperProcessor\n",
        "import torch\n",
        "import torchaudio\n",
        "from tqdm import tqdm\n",
        "\n",
        "base_model = \"openai/whisper-small\"\n",
        "\n",
        "params = [\n",
        "          (\"00\", \"00\"),\n",
        "          (\"05\", \"05\"),\n",
        "          (\"15\", \"15\"),\n",
        "          (\"25\", \"25\"),\n",
        "          (\"35\", \"35\"),\n",
        "          (\"05\", \"25\"),\n",
        "          (\"25\", \"05\"),\n",
        "          (\"15\", \"35\"),\n",
        "          (\"35\", \"15\"),\n",
        "          (\"00\", \"50\"),\n",
        "          (\"50\", \"00\"),\n",
        "          (\"50\", \"50\"),\n",
        "]\n",
        "model_paths = [base_model] + \\\n",
        "              [f\"victors3136/whisper-model-small-ro-finetune-5k-{it}-{sp}\" for it, sp in params]\n",
        "language = \"ro\"\n",
        "task = \"transcribe\"\n",
        "split = \"test\"\n",
        "max_samples = 1_000\n",
        "\n",
        "def speech_file_to_array_fn(batch):\n",
        "    speech_array, _ = torchaudio.load(batch[\"audio\"][\"path\"])\n",
        "    batch[\"speech\"] = speech_array[0].numpy()\n",
        "    batch[\"target_text\"] = batch[\"sentence\"].lower()\n",
        "    return batch\n",
        "\n",
        "\n",
        "print(\"Loading Common Voice Romanian test data...\")\n",
        "dataset = load_dataset(\"mozilla-foundation/common_voice_11_0\", language, split=split)\\\n",
        "            .filter(lambda x: x[\"sentence\"] is not None and x[\"audio\"] is not None)\n",
        "dataset = dataset.select(range(min(max_samples, len(dataset))))\\\n",
        "            .map(speech_file_to_array_fn, num_proc=4)\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(base_model, language=language, task=task)\n",
        "\n",
        "preprocessed_inputs = [\n",
        "    {\n",
        "        \"input_features\": processor(audio=sample[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\").input_features,\n",
        "        \"target_text\": sample[\"target_text\"]\n",
        "    }\n",
        "    for sample in tqdm(dataset, desc=\"Preprocessing inputs\")\n",
        "]\n",
        "\n",
        "results = {}\n",
        "for model_id in model_paths:\n",
        "    print(f\"\\nEvaluating {model_id}...\")\n",
        "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "        model_id,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "    model.config.forced_decoder_ids = processor.get_decoder_prompt_ids()\n",
        "    predictions = []\n",
        "    references = []\n",
        "    for sample in tqdm(preprocessed_inputs, desc=f\"Benchmarking {model_id}...\"):\n",
        "        inputs = {\"input_features\": sample[\"input_features\"].to(model.device)}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predicted_ids = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=225,\n",
        "                language=\"ro\",\n",
        "                task=\"transcribe\"\n",
        "            )\n",
        "\n",
        "        transcription = processor.batch_decode(\n",
        "            predicted_ids,\n",
        "            skip_special_tokens=True,\n",
        "            normalize=True\n",
        "        )[0]\n",
        "        predictions.append(transcription)\n",
        "        references.append(sample['target_text'])\n",
        "\n",
        "\n",
        "    wer_score = wer(references, predictions)\n",
        "    cer_score = cer(references, predictions)\n",
        "    results[model_id] = {\"wer\": wer_score, \"cer\": cer_score}\n",
        "\n",
        "results"
      ]
    }
  ]
}